spring:
  kafka:
    consumer:
      auto-offset-reset: latest
#      auto-offset-reset: earliest
      group-id: streamer
      enable-auto-commit: true
#      max.poll.interval.ms: 5000
#      max.poll.records: 50
    producer:
      client-id: streamer
    bootstrap-servers: ["${BROKER_LIST}"]
  application:
    name: streamer
  data:
    mongodb:
      uri: mongodb://${MONGO}/collector.pages
server:
  port: ${SERVER_PORT}

#根据设置的master.uri来决定部署模式是什么样的，这儿是用standalone模式，也可以运行在yarn上
collector.spark.master.uri: spark://${SPARK}:7077
#mongodb collection名字，用于保存三端上报的页面浏览信息
collector.mongo.page: pages
#mongodb collection名字，用于保存按时间维度计算出的每分钟的pv uv结果
collector.mongo.minute: minutes
#mongodb collection名字，用于保存按时间维度计算出的每小时的pv uv结果
collector.mongo.hour: hours
#mongodb collection名字，用于保存按时间维度计算出的每天的pv uv结果
collector.mongo.day: days


#按时间维度计算每分钟的pv uv结果保存的kafka topic
streamer.kafka.minute: "streamer.minute"
#按更多维度计算每分钟的pv uv结果保存的kafka topic
streamer.kafka.minute.rich: "streamer.minute.rich"
#按时间维度计算每分钟的pv uv的检查点路径
streamer.hdfs.minute: "hdfs://${HDFS}/streamer/minute"
#按更多维度计算每分钟的pv uv的检查点路径
streamer.hdfs.rich.minute: "hdfs://${HDFS}/streamer/rich_minute"

#spark程序资源配置
spark.driver.cores: ${DRIVER_CORES}
spark.driver.memory: ${DRIVER_MEMORY}
spark.executor.cores: ${EXECUTOR_CORES}
spark.executor.memory: ${EXECUTOR_MEMORY}

---

spring:
  profiles:
    active: ${ACTIVE_PROFILE:dev}

